"""
Greg McInes
Altman Lab
gmcinnes@stanford.edu
"""

# Load packages
import argparse
import sys
import pandas as pd
import numpy as np
import os
from keras.models import load_model, model_from_json


class HubblePredict(object):
    def __init__(self, seq_file, out_file, debug):

        # Set global variables
        self.seq_file = seq_file
        self.out_file = out_file
        self.debug = debug

        # Load annotation embeddings
        self.embeddings = self.create_embedding_matrix()

        # Generate predictions
        self.run()

    def run(self):
        if self.debug:
            print("Generating Hubble.2D6 Predictions")

        # Load data
        data = self.load_data()

        # Predict
        predicted_scores = self.predict(data)

        # Compile output
        functions = self.score_to_function(predicted_scores)


        # Print output
        self.print_result(data['sample_names'], functions)


    def predict(self, data):
        # Get list of model paths to use
        model_list = self.fetch_models()

        # Set the variable to store the scores in
        predicted_scores = None

        # For each model, load it and generate scores
        for m in model_list:
            if self.debug:
                print("Processing model: %s" % m)

            # Load the model definition
            json_file = open('%s.json' % m, 'r')
            loaded_model_json = json_file.read()
            model = model_from_json(loaded_model_json)
            json_file.close()

            # Load the weights to the model
            model.load_weights("%s.model.h5" % m)

            # Generate predictions
            y_pred_values = model.predict([data['X']])

            # Store the results in a matrix. If it's the first pass initiate the matrix, otherwise stack.
            if predicted_scores is None:
                predicted_scores = y_pred_values
            else:
                predicted_scores = np.dstack((predicted_scores, y_pred_values))

        return predicted_scores


    def score_to_function(self, predicted_scores):
        # Convert the star allele scores into discrete functions

        # Get the mean scores from the ensemble
        mean_predicted_scores = np.mean(predicted_scores, axis=2)

        # These are the rules for defining the functions from the two scores generated by the models

        # Greater than both -> normal
        # Less than both -> no function
        # Greater than 1 less than equal to 2 -> decreased

        # These cutpoints were defined elsewhere
        cutpoint_1 = 0.4260022
        cutpoint_2 = 0.7360413

        cuts = np.greater(mean_predicted_scores, [cutpoint_1, cutpoint_2])

        functions = []
        for i in range(cuts.shape[0]):
            scores = cuts[i]
            if np.array_equal(scores, np.array([True, True])):
                functions.append("Normal Function")
            elif np.array_equal(scores, np.array([True, False])):
                functions.append("Decreased Function")
            else:
                functions.append("No Function")

        return functions

    def fetch_models(self):

        # Get path to model directory
        wd = sys.path[0]
        model_dir = os.path.join(wd, "../models/")

        # Get list of model names
        model_prefix = "hubble2d6"
        model_names = ["%s_%s" % (model_prefix, x) for x in range(7)]

        # Create list of models with full paths
        models = [os.path.join(model_dir, x) for x in model_names]

        return models

    def load_data(self):

        sample_names = []
        seqs = []

        # This value is the index for the null vector, i.e. no annotations at all
        null_vector = 2048

        # Load the values from the file
        with open(self.seq_file) as f:
            for line in f:
                fields = line.rstrip().split()
                sample_names.append(fields[0])

                # Concatenate the sequence indices fields together
                seq1 = [int(x) for x in fields[1].split(',')]
                seq2 = [int(x) for x in fields[2].split(',')]
                null = [null_vector] * 32
                seq = seq1 + null + seq2
                seqs.append(seq)

        # Convert the indices to embeddings
        X_ind = np.array(seqs)
        X = self.indices2embeddings(X_ind)

        # Put the data in a dictionary and return
        parsed_data = {
            "X": X,
            "sample_names": sample_names
        }

        return parsed_data

    # Load the variant embeddings from file
    def create_embedding_matrix(self):
        wd = sys.path[0]
        file = os.path.join(wd, "../data/gvcf2seq.annotation_embeddings.csv")
        embeddings_df = pd.read_csv(file)
        embedding_matrix = embeddings_df.loc[:, embeddings_df.columns != 'key'].values.astype(np.float)
        return embedding_matrix

    # Transform the embedding indices to the actual embeddings
    def indices2embeddings(self, data):
        embeddings = np.apply_along_axis(self.embedding_mapper, axis=1, arr=data)
        return(embeddings)

    def embedding_mapper(self, x):
        return self.embeddings[x]

    def print_result(self, sample_names, functions):
        f = open(self.out_file, "w")
        f.write("Sample\tPredictedFunction\n")
        for i in range(len(sample_names)):
            f.write("%s\t%s\n" % (sample_names[i], functions[i]))

"""
Parse the command line
"""
def parse_command_line():
    parser = argparse.ArgumentParser(
        description = 'CYP2D6 star allele function predictions by Hubble.2D6')
    parser.add_argument("-f", "--file", help="Input")
    parser.add_argument("-o", "--out", help="Output file")
    parser.add_argument("-d", "--debug", action='store_true', default=False,
                                help="Output debugging messages.  May be very verbose.")
    options = parser.parse_args()
    return options


"""
Main
"""
if __name__ == "__main__":
    options = parse_command_line()
    HubblePredict(options.file, options.out, options.debug)

